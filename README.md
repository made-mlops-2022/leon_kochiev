Первый запуск:
```bash
docker-compose up --build
```
Если у вас есть проблемы с образом airflow-ml-base его надо собрать руками и потом запустить:
```bash
cd
DOCKER_BUILDKIT=0 docker build -t airflow-ml-base:latest .
docker-compose up
```

Остановка:
```bash
docker-compose stop
```

Возобновить работу:
```bash
docker-compose up
```

Тесты:
```bash
pytest
```
Добавила в data папку models и transformers для тестов

0. Поднимите airflow локально, используя docker compose

1. Реализуйте dag, который генерирует данные для обучения модели (5/5 баллов)

2. Реализуйте dag, который обучает модель еженедельно, используя данные за текущий день. (10/10 баллов)

3. Реализуйте dag, который использует модель ежедневно (5/5 баллов)

4. все даги реализованы только с помощью DockerOperator (10/10 баллов)

5. Традиционно, самооценка (1/1 балл)

Дополнительная часть:

1. Реализуйте сенсоры на то, что данные готовы для дагов тренировки и обучения (3/3 доп балла)
2. Протестируйте ваши даги https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html (5/5 доп баллов)
3. В docker compose так же настройте поднятие mlflow и запишите туда параметры обучения, метрики и артефакт (модель) (0/5 доп баллов)
4. Вместо пути в airflow variables используйте API Mlflow Model Registry. Даг для инференса должен подхватывать последнюю продакшен модель (0/5 доп баллов)
5. Настройте alert в случае падения дага (3/3 доп балла)

Итого: 42 балла
